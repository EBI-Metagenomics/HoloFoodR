---
title: "ECCB Paper HoloFood Salmon - MOFA2 Analysis"
date: "`r Sys.Date()`"
package: HoloFoodR
output:
    BiocStyle::html_document:
        fig_height: 7
        fig_width: 10
        toc: yes
        toc_depth: 2
        number_sections: true
vignette: >
    %\VignetteIndexEntry{mia}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(knitr)
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>",
    cache = TRUE
)
```

```{r setup}
# List of packages that we need
packages <- c(
    "ggplot2", "knitr", "mia", "dplyr", "miaViz", "MOFA2",  "patchwork", "reticulate",
    "MGnifyR", "reshape2", "GGally", "IntegratedLearner", "SuperLearner",
    "bartMachine", "mcmcplots", "tidyverse", "UpSetR", "shadowtext", "ComplexHeatmap",
    "stringr", "cowplot", "caret", "scater"
    )

# Get packages that are already installed installed
packages_already_installed <- packages[ packages %in% installed.packages() ]

# Get packages that need to be installed
packages_need_to_install <- setdiff( packages, packages_already_installed )

# Loads BiocManager into the session. Install it if it not already installed.
if( !require("BiocManager") ){
    install.packages("BiocManager")
    library("BiocManager")
}

# If there are packages that need to be installed, installs them with BiocManager
# Updates old packages.
if( length(packages_need_to_install) > 0 ) {
   install(packages_need_to_install, ask = FALSE)
}

# Load all packages into session. Stop if there are packages that were not
# successfully loaded
pkgs_not_loaded <- !sapply(packages, require, character.only = TRUE)
pkgs_not_loaded <- names(pkgs_not_loaded)[ pkgs_not_loaded ]
if( length(pkgs_not_loaded) > 0 ){
    stop("Error in loading the following packages into the session: '", paste0(pkgs_not_loaded, collapse = "', '"), "'")
}
```

```{r}
# Provide Java with RAM
options(java.parameters = "-Xmx8g")
```

## Import data

### Retrieve HoloFood data

Firstly, we have to query the HoloFood database to retrieve the salmon accession
numbers.

```{r get_animals, eval=FALSE}
# Get salmon samples
salmons <- HoloFoodR::doQuery("animals", system = "salmon", use.cache = TRUE)

# Get only salmon metagenomic and fatty acid data
salmons <- salmons |>
  filter(fatty_acids == TRUE & metagenomic_assembly == TRUE)
```

Next, we can retrieve the data associated with each salmon.

```{r get_animal_data, eval=FALSE}
# Get salmon data
salmon_data <- HoloFoodR::getData(
  accession.type = "animals",
  accession = salmons[["accession"]],
  use.cache = TRUE
)

# Get salmon samples
salmon_samples <- salmon_data[["samples"]]

# Get sample IDs
salmon_sample_ids <- unique(salmon_samples[["accession"]])

# Show salmon data
head(salmon_data[[2]])
```

Finally, we can retrieve the data from each sample of each sample (for instance,
metagenomic, metabolomic, transcriptomic, etc.) and store the result in a
MultiAssayExperiment object.

```{r get_samples, eval=FALSE}
# Get salmon MAE experiments as MAE object
mae <- HoloFoodR::getResult(
  salmon_sample_ids,
  use.cache = TRUE
)

# Save salmon MAE
saveRDS(object = mae, file = "../inst/extdata/salmon_mae_without_mgnify.RDS")

# Show available salmon experiments
experiments(mae)
```

### Fetch metagenomic data from MGnify

HoloFood database does not include the data for metagenomic assemblies, which
can be retrieved from the [MGnify portal](https://www.ebi.ac.uk/metagenomics).

```{r get_metagenomic_samples, eval=FALSE}
# Create MGnify object
mg <- MgnifyClient(
  useCache = TRUE,
  cacheDir = ".MGnifyR_cache"
)

# Select only metagenomic assembly samples types
metagenomic_salmon_samples <- salmon_samples[
  salmon_samples[["sample_type"]] == "metagenomic_assembly",
]

# Search for sample IDs in MGnify database
salmon_analysis_ids <- searchAnalysis(
  mg,
  type = "samples",
  metagenomic_salmon_samples[["accession"]]
)
```

```{r get_metagenomic, eval=FALSE}
# Get metagenomic taxonomic data for salmon from MGnify
tse <- MGnifyR::getResult(
  x = mg,
  accession = salmon_analysis_ids,
  get.func = FALSE
)

# Save salmon_metagenomic_tse
saveRDS <- saveRDS(object = tse, file = "../inst/extdata/salmon_metagenomic_tse.RDS")

tse <- readRDS("../inst/extdata/salmon_metagenomic_tse.RDS")
```

Data fetched from MGnify has MGnify-specific identifiers. We have to first
rename samples with HoloFood specific ID and then add the data to
MultiAssayExperiment combining all the data.


```{r add_metagenomic_data, eval=FALSE}
.add_MGnify <- function(
        mae, tse, holofood.id = "sample_biosample",
        exp.name = "metagenomic_assembly", new.exp = "metagenomic",
        replace = TRUE){
    # Rename columns based on HoloFood ID
    colnames(tse) <- colData(tse)[[holofood.id]]

    # Merge add MGnify metagenomic data to the existing metagenomic_assembly
    # experiment. Get the experiment from HoloFood data.
    tse2 <- mae[[exp.name]]

    # Combine sample metadata
    cd1 <- as.data.frame(colData(tse))
    cd2 <- as.data.frame(colData(tse2))
    cd <- merge(
        cd1, cd2,
        by.x = holofood.id,
        by.y = "accession",
        all.x = TRUE
    )
    rownames(cd) <- cd[[holofood.id]]

    # Now order colData to ensure that order is correct
    cd <- cd[colnames(tse), ]

    # Add it to TreeSE
    colData(tse) <- DataFrame(cd, check.names = FALSE)

    # Rename to match Holofood
    colnames(tse) <- colData(tse)[[holofood.id]]

    # Now order the data based on TreeSE in MAE
    # First take those columns that can be found
    mae[[exp.name]] <- mae[[exp.name]][
        , colnames(mae[[exp.name]]) %in% colnames(tse) ]

    # Then order
    tse <- tse[, match(colnames(mae[[exp.name]]), colnames(tse))]
    # And add to MAE in place of old experiment
    if( replace ){
        mae[[exp.name]] <- tse
    } else{
        # Get sample map
        sample_map <- sampleMap(mae)
        # Get samples that are matching with those one that are being added
        add_sample_map <- sample_map[
            match(colnames(tse), sample_map[["colname"]]), ]
        # Rename the experiment
        add_sample_map[["assay"]] <- new.exp
        # Add to sample map'
        sample_map <- rbind(sample_map, add_sample_map)
        # Create MAE
        tse <- ExperimentList(temp = tse)
        names(tse) <- new.exp

        exp_list <- c(experiments(mae), tse)
        mae <- MultiAssayExperiment(
            exp_list, colData = colData(mae), sampleMap = sample_map)
    }
    return(mae)
}

mae <- .add_MGnify(mae, tse)

# Save to merged MAE object to RDS
saveRDS(object = mae, file = "../inst/extdata/salmon_mae.RDS")
```

## Data preprocess

Now we can pre-process data and prepared it for subsequent analyses.

```{r load_data}
path <- system.file("extdata", "salmon_mae.RDS", package = "HoloFoodR")
#salmon_mae <- readRDS(path)
# mae <- readRDS(path)
mae <- readRDS("../inst/extdata/salmon_mae.RDS")

# Fetch only experiments that we need
mae <- mae[, , c("FATTY ACIDS MG", "metagenomic_assembly")]
```

```{r preprocess}
# From metabolite data, remove organ-fatty acids row as it only contains a
# string value "muscle"
tse <- mae[[1]]
tse <- tse[!(rowData(tse)[["marker.name"]] %in% c("Organ-fatty acids")), ]
mae[[1]] <- tse

# Transform matrices to numeric. Some values are "< 0.01"
# If a number is < 0.01, assume it to be 0
assay <- assay(mae[[1]], "counts")
assay[ assay == "<0.01" ] <- 0
assay <- apply(assay, c(1, 2), function(x) as.numeric(gsub(",", ".", x)))

# Reassign assay back to MAE
assay(mae[[1]], "counts") <- assay

# From metagenomic data, remove those rows that do not have taxonomy info
not_empty <- !apply(rowData(mae[[2]]), 1, function(x) all(is.na(x)))
mae[[2]] <- mae[[2]][ not_empty, ]
```

For demonstration purposes, we will focus on investigating two experiments 
(`FATTY ACIDS MG` and `metagenomic_assembly`) within the trial A performed by 
the HoloFood consortium. This trial the health effects of fermented seaweed added 
to the diet of salmons.

```{r preprocess2}
# Filter MAE object to include only Trial A
mae <- mae[ , colData(mae)[["Trial code"]] == "SA", ]
mae
```

We log-transform fatty acid assay to approximate it to normal distribution.

```{r transformation_fatty_acids}
# Transform fatty acids in mg with log10
mae[[1]] <- transformAssay(
    mae[[1]],
    assay.type = "counts",
    MARGIN = "samples",
    method = "log10",
    pseudocount = TRUE
)
```

```{r transformation_metagenomics}
# Agglomerate metagenomic data to Genus level and add it to altExp slot
rank <- "Genus"
altExp(mae[[2]], rank) <- agglomerateByRank(mae[[2]], rank, na.rm = TRUE)

# Transform microbiome with centered log-ratio method
altExp(mae[[2]], rank) <- transformAssay(
    altExp(mae[[2]], rank), method = "relabundance")
altExp(mae[[2]], rank) <- transformAssay(
    altExp(mae[[2]], rank), assay.type = "relabundance", method = "clr", pseudocount = TRUE)
```


```{r}
# For cross-correlation analysis and MOFA2, replace original metagenomics data
# with agglomerated one
mae_sub <- mae # Keep original MAE intact
mae_sub[[2]] <- altExp(mae_sub[[2]], rank)

# Filter genera by prevalence and add it to altExp slot
altExp(mae_sub[[2]], "prev_genus") <- subsetByPrevalentFeatures(mae_sub[[2]], prevalence = 0.2, detection = 0.001)

# Add Treatment concentration to alternative experiment
# Note that host.diet.treatment.concentration variable is different,
# and it is 0 for control and all other treatments except for maximum
# concentration (2, Jaguar treatment code)
mae_coldata_animal <- colData(mae)[, c("animal", "Treatment concentration")]
colData(altExp(mae_sub[[2]], "prev_genus")) <-
  merge(colData(altExp(mae_sub[[2]], "prev_genus")), mae_coldata_animal, by = "animal")

# Add control vs treatment groups
colData(altExp(mae_sub[[2]], "prev_genus"))["treatment_group"] <- ifelse(
  colData(altExp(mae_sub[[2]], "prev_genus"))[, "Treatment concentration"] == 0, "control", "treatment"
)

# Extract only transformed metabolomic assays
assays(mae_sub[[1]]) <- assays(mae_sub[[1]])[names(assays(mae_sub[[1]])) %in% c("log10")]

# Rename column names to make them more consistent
names(colData(mae_sub)) <- tolower(gsub(" ", "_", names(colData(mae_sub))))

# Add salmon host mass to colData
merged_coldata <- merge(x = colData(mae_sub), y = colData(mae_sub[[2]])[c("animal", "host.gutted.mass")], all.x = TRUE, by = "animal")
rownames(merged_coldata) <- merged_coldata$animal
colData(mae_sub) <- merged_coldata

# Add control vs treatment groups
colData(mae_sub)["treatment_group"] <- ifelse(
  colData(mae_sub)[, "treatment_concentration"] == 0, "control", "treatment"
)

# Take those samples that can be found from both experiments
mae_sub <- intersectColumns(mae_sub)
```

## Data exploration

```{r show_metadata2}
# Display columns of MAE object to select those of interest
colData(mae) |> names()
```

### Abundance plot

And abundance plot of centered-log-ratio transformed metagenomic species
is important for general understanding of the data. Additionally,
we also indicate "control" and "treatment" groups with colors for initial
assessment of difference between the groups.

```{r plot_abundance}
plotAbundanceDensity(altExp(mae_sub[[2]], "prev_genus"), assay.type = "clr", colour_by = "treatment_group")
```

_Mycoplasma_ has bee shown to be associated with positive health effects
(https://doi-org.ezproxy.utu.fi/10.1186/s42523-021-00096-2) and is generally
predominant in salmons (https://doi-org.ezproxy.utu.fi/10.1007/s00248-002-1011-6).

The addition of treatment does not change the weight of salmons.

## Perform cross-association analysis

Before cross-association analysis, we can filter out all features with
standard deviation equal to 0 to avoid warnings from the cross-association
function.


```{r filter_0_sd}

altExp(mae_sub[[1]], "not_sd_0") <- mae_sub[[1]][apply(assay(mae_sub[[1]], "log10"), 1, sd) != 0, ]

```


```{r cross_association_analysis}
#| fig-width: 15
#| fig-height: 15


# Perform cross-association analysis
res <- testExperimentCrossAssociation(
    mae_sub,
    experiment1 = 1, 
    experiment2 = 2,
    altexp1 = "not_sd_0",
    altexp2 = "prev_genus",
    method = "kendall",
    assay.type1 = "log10",
    assay.type2 = "clr",
    mode = "matrix"
    )

# Create a heatmap and store it
plot <- Heatmap(
    res$cor,
    # Print values to cells
    cell_fun = function(j, i, x, y, width, height, fill) {
        # If the p-value is under threshold
        if( !is.na(res$p_adj[i, j]) & res$p_adj[i, j] < 0.05 ){
            # Print "X"
          grid.shadowtext(sprintf("%s", "X"), x, y, gp = gpar(fontsize = 10, col = "white"))
        }
    },
    heatmap_legend_param = list(title = "", legend_height = unit(10, "cm"))
)

draw(plot, padding = unit(c(2, 20, 2, 25), "mm"))
```

## PCoA with beta-diversity

We can perform PCoA analysis based on Bray-Curtis index and visualize the
results with explained variances on axis.

```{r}
# Add treatment group (treatment or control) to metagenomic table
tse <- mae_sub[[2]]
colData(tse) <- merge(colData(tse), colData(mae_sub)[, c("animal", "treatment_group")], by = "animal")

tse_pcoa <- runMDS(tse,
                   FUN = vegan::vegdist,
                   methods = "bray",
                   assay.type = "relabundance",
                   name = "MDS_bray")

p <- plotReducedDim(tse_pcoa, "MDS_bray",
                    colour_by = "treatment_group")

# Calculate explained variance
e <- attr(reducedDim(tse_pcoa, "MDS_bray"), "eig")
rel_eig <- e / sum(e[e > 0])

# Add explained variance for each axis
p <- p + labs(x = paste("PCoA 1 (", round(100 * rel_eig[[1]], 1),
                        "%", ")", sep = ""),
              y = paste("PCoA 2 (", round(100 * rel_eig[[2]], 1),
                        "%", ")", sep = ""))

p
```

It seems that control and treatment groups are not dissimilar.

We can also apply different methods on the same data and visualize the
results.

```{r}
# Run NMDS on relabundance assay with Bray-Curtis distances
tse_pcoa <- runNMDS(tse_pcoa,
               FUN = vegan::vegdist,
               method = "bray",
               assay.type = "relabundance",
               name = "NMDS_bray")

# Run MDS on clr assay with Aitchison distances
tse_pcoa <- runMDS(tse_pcoa,
              FUN = vegan::vegdist,
              method = "euclidean",
              assay.type = "clr",
              name = "MDS_aitchison")

# Run NMDS on clr assay with Euclidean distances
tse_pcoa <- runNMDS(tse_pcoa,
               FUN = vegan::vegdist,
               method = "euclidean",
               assay.type = "clr",
               name = "NMDS_aitchison")



plots <- lapply(c("MDS_bray", "MDS_aitchison",
                  "NMDS_bray", "NMDS_aitchison"),
                plotReducedDim,
                object = tse_pcoa,
                colour_by = "treatment_group")

# Generate multi-panel plot
wrap_plots(plots) +
  plot_layout(guides = "collect")
```
All four methods demonstrate that features from control and treatment are
not dissimilar.

## MOFA analysis

Multi-omic factor analysis allows us to discover latent factors that underlie
the biological differences by taking in consideration 2 or more omic assays.
To cite the original auther, "MOFA can be viewed as a statistically rigorous
generalization of (sparse) principal component analysis (PCA) to multi-omics
data".

We will use multi-group functionality and try to find the shared and exclusive
variability between two groups of salmons at day 60 (after treatment).

1. Heavy salmons that weigh more than than median
2. Light salmons that weigh less than median

Since we could not find any differentiation between salmons in control and
treatment groups, we would like to know if any of metagenomic species or fatty
acids drive the difference in salmon weight.


```{r mofa_fit}
# Fetch only salmons at day 60
mae_day_60 <- mae_sub[, colData(mae[[2]])$trial.timepoint == 60]

# Add mass categories
mass_median <- median(as.numeric(colData(mae_day_60)[, "host.gutted.mass"]))
colData(mae_day_60)["mass_category"] <- ifelse(
  as.numeric(colData(mae_day_60)[, "host.gutted.mass"]) > mass_median, "heavy", "light"
)

# Add Mycoplasma abundance category
relabundance <- assay(mae_day_60[[2]], "relabundance")["Mycoplasma", ]
threshold <- 0.8

colData(mae_day_60)$mycoplasma_abundance <- ifelse(relabundance > 0.8, "abundant", "not_abundant")


# Add Aliivibrio abundance category
relabundance <- assay(mae_day_60[[2]], "relabundance")["Aliivibrio", ]
threshold <- 0.8

colData(mae_day_60)$aliivibrio_abundance <- ifelse(relabundance > 0.1, "abundant", "not_abundant")

# Select only the columns we require
colData(mae_day_60) <- colData(mae_day_60)[ , c("treatment_code", treatment_group, "host.gutted.mass", "mass_category", "mycoplasma_abundance", "aliivibrio_abundance"), drop = FALSE]



# Extract only transformed metagenomic assays for MOFA+ analysis
assays(mae_day_60[[2]]) <- assays(mae_day_60[[2]])[names(assays(mae_day_60[[2]])) %in% c("clr")]

# Transform MAE object to MultiAssayExperiment
model <- create_mofa_from_MultiAssayExperiment(
    mae_day_60,
    group = "mass_category",
    extract_metadata = TRUE
)

# Set model's options
model_opts <- get_default_model_options(model)
model_opts$num_factors <- 5
train_opts <- get_default_training_options(model)

# Change convergence mode to slightly improve accuracy
train_opts$convergence_mode <- "medium"

# Prepare MOFA model
model <- prepare_mofa(
  object = model,
  model_options = model_opts,
  training_options = train_opts
)

# Train model
model <- run_mofa(model, use_basilisk = TRUE)
```

## Pearson correlation between factors

For sanity check, we expect factors to be uncorrelated.

```{r check_ft}
#| fig-width: 10
plot_factor_cor(
  model,
  method = "pearson",
  cl.ratio = 0.2,
  tl.srt = 0,
  title = "Pearson correlation between factors",
  mar=c(0, 0, 2, 0),
)
```
Overall, we do not observe highly correlated factors which is the

## Visualization of MOFA analysis

### Variance explained

Next, we will plot the variances explained by each factor.


```{r var_factor1}
plot_variance_explained(model, x = "group", y = "view", factor = 1, legend = T)
```

Factor 1 captures the variances explained in fatty acid view across both
mass categories.


```{r var_factor2}
plot_variance_explained(model, x = "group", y = "view", factor = 2, legend = T)
```

On the other hand, factor 2 captures variance explained in metagenomic view,
also across both mass categories.

```{r var_factor3}
plot_variance_explained(model, x = "group", y = "view", factor = 3, legend = T)
```
Factor 3 is similar to factor 2 but the variance expliend numbers are slighly
lower.

```{r var_factor4}
plot_variance_explained(model, x = "group", y = "view", factor = 4, legend = T)
```
Factor 4 switches back to fatty acid view, but the variance explained is much
lower.

```{r var_factor5}
plot_variance_explained(model, x = "group", y = "view", factor = 5, legend = T)
```

Finally, Factor 5 explains the rest of the variance in fatty acid view.

## Plot factor

We can now plot single factors. For demonstration purposes, we will focus on
the first factor and color the samples by mass category.

```{r plot_factor}


plot_factor(model,
  factors = 2,
  color_by = "aliivibrio_abundance",
  scale = TRUE,
  # group_by = "mycoplasma_abundance",
  add_violin = TRUE,
  color_violin = TRUE, 
) 
  # labs(fill = "Treatment group") +
  # scale_fill_hue(
  #   labels = c(
  #     "Control", "Treatment"
  #   )
  # ) +
  # labs(y = "Factor 2")

plot_factor(model,
  factor = 1,
  color_by = "treatment_group", 
  dot_size = 1.5,
  scale = TRUE, legend = FALSE
)
```

```{r}
plot_variance_explained(model, x = "group")
```


We can observer, the the Tiger (control), and Jaguar (2% algae concentration)
have very similar patters with factor values that are concentrated in the lower
part of the violin plots for "heavy" salmons.

## Plot weights

The next step is to have a deeper look inside the observations we found above.
We can plot factor weight that should show us what fatty acids and bacterial
genera have the highest positive or negative impact on the selected factors.

### Plot top weights

It is possible to plot top weight per each view per each factor.

```{r top_weight_visualization, fig.width=8}
custom_plotter <- function(name, factor) {
    p <- plot_top_weights(
        model,
        view = name,
        factors = factor,
        nfeatures = 10
    ) +
    labs(title = paste0("Top weights of the ", name, " assay for factor ", factor))
    return(p)
}

custom_plotter("FATTY ACIDS MG", factor = 1)
custom_plotter("FATTY ACIDS MG", factor = 2)
custom_plotter("FATTY ACIDS MG", factor = 3)
custom_plotter("metagenomic_assembly", factor = 2)
```
If you focus on the first plot, which depicts the top factor weights of the
factor 1 of the fatty acid view,  you will notice that all fatty acids have
negative weights on factor 1. By taking into consideration what we observed on
the factor plot above, we can say that all these acids have lower concentrations
in most of heavy salmons within control (Tiger) and maximum concentration
treatments (Jaguar).

A better view can be offered if we color samples by their individual masses
instead of relying on median. Almost all "heavy" salmons have low concentrations
of the acids seen above.

```{r plot_factor_by_mass}
plot_factor(model,
  factors = 1,
  color_by = "host.gutted.mass",
  group_by = "treatment_code",
)
```

An interesting example comes from an unknown fatty acid 16:4n-3, which exhibits
the diametrically opposed effects in factors 1 and 3 compared to factor 2.
Specifically, it has the largest effects in factors 2 and 3, in the former case
the effect is positive, whereas in the latter case it is negative. Conversely,
it has second most significant negative effect on factor 1.

Similarly, these plots shows us that factors 2 and 3 mostly likely describe two
different treatments, which have the opposite impacts on the concentrations
of fatty acids.

### Plot weights per factor

We can also plot top weights per view for a selection of factors to have a better
overview of the impacts of different features on factors.

```{r weight_visualization2, fig.width=15}
plot_weights(
    model,
    view = 1,
    nfeatures = 8,
    factors = 1:3,
    text_size = 4,
    ) +
    labs(title = "Top 10 weights for the first three factors in fatty acid view") +
  theme(plot.title = element_text(size = 25),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15)
  )
```

These graphs provide us with more high-level overview of the impacts of
the fatty acids on the factors.

We can observe that some fatty acids, such as lignoceric acid, are strongly positively associated with factor 2. Lignoceric acid, however, is negatively associated with factor 3, suggesting  that these factors describe distinct biological processes that underlie
these two factors. Conversely, gamma-linolenic acid has the opposite effects in factor 2 and factor 3. It is negatively associated with factor 2 and positively with factor 3.

Moreover, several other fatty acids differentiate the factors 2 and 3:

1. Nervonic acid (an analog of lignoceric acid)
2. Myristoleic acid
3. Paulinic acid
4. Margaric acid
5. Unknown fatty acid 16:4-3

The factor 1 has two negatively associated fatty acids in common with factor 3:
nervonic and paulinic acids. Most likely, factors 1 and 3 describe two similar underlying processes but it remains to be clarified why only these two acids
are common between the two factors. Finally, one can pose a question of
why factor 3 contains lignoceric and its analog nervonic acids, while only the former
appears in factor 3.

## Plot Factors

### Multiple Factors

We can plot multiple latent factors on a scatter plot.

```{r factor_visualization}
plot_factors(model, factors = c(1, 2, 3), color_by = "treatment_code")
```

It can be noticed that scatter plots between factors 1 and 2, and factors 2 and 3,
display two clusters:

1. The first containing exclusively Tiger (control) and Jaguar (2.0% concentration
of algae, the highest) treatment groups
2. The second containing a mixture of all groups

These plots demonstrate that we need to investigate the first cluster further
because the control and the Jaguar treatment groups might be intuitively expected
to be in two distinct clusters that reflect their opposing treatments.

These clusters are found by a non-linear dimensional reduction technique
Uniform Manifold Approximation and Projection for Dimension Reduction.

## Plot covariation patterns

```{r, fig.width=10}
# Heatmap of relationships between factor and top features
plot_data_heatmap(
    model,
    view = 1,
    factor = 1,
    features = 20,
    cluster_rows = TRUE, cluster_cols = FALSE,
    show_rownames = TRUE, show_colnames = FALSE,
    main = "Heatmap of top 20 fatty acids weight captured by factor 1"
)
```


## Non-linear dimensionality reduction

Finally, we can use trained MOFA model to cluster the samples by using non-linear methods, such as Uniform Manifold Approximation and Projection for Dimension Reduction (UMAP).

### UMAP

```{r umap}
set.seed(142)
model <- run_umap(model)

plot_dimred(
  model,
  method = "UMAP",
  color_by = "treatment_code"
) +
  labs(title = "UMAP plot of MOFA model")
```
As noted, above we also observe the same two clusters, first seen in the
scatter plots of factors.


### MOFA2 model by group

We can also find sources of variability that drive each group and find out
which sources are shared or different between the groups.

```{r mofa_group}
# Remove near-zero-variances from metagenomic assembly assay
nzv <- nearZeroVar(t(assay(mae_sub[[2]])))
no_var <- t(assay(mae_sub[[2]])[-nzv, ])
no_var <- t(no_var)
mae_sub_no_var <- mae_sub
mae_sub_no_var <- mae_sub[rownames(no_var), ,]
mae_sub_no_var[[1]] <- mae_sub[[1]]

# Transform mass category to factor
colData(mae_sub_no_var)$mass_category <- as.factor(colData(mae_sub_no_var)$mass_category)

model <- create_mofa_from_MultiAssayExperiment(
    mae_sub_no_var,
    group = "treatment_group",
    extract_metadata = TRUE
)

# Set model's options
model_opts <- get_default_model_options(model)
model_opts$num_factors <- 5
train_opts <- get_default_training_options(model)

# Change convergence mode to slightly improve accuracy
train_opts$convergence_mode <- "medium"

# Prepare MOFA model
model <- prepare_mofa(
  object = model,
  model_options = model_opts,
  training_options = train_opts
)

# Train model
model <- run_mofa(model, use_basilisk = TRUE)
```


```{r}
#| fig-width: 10
plot_variance_explained(model, x = "group", y = "view")
```

```{r}
colors <- c(
  "heavy" = "grey70",
  "light" = "#CD3278"
)

plot_factor(model,
            factor = 1,
            color_by = "mass_category", 
            scale = TRUE, 
            add_violin = TRUE, color_violin = TRUE, 
            dodge = TRUE, dot_size = 1, legend = TRUE
) + scale_color_manual(values=colors) + scale_fill_manual(values=colors)


plot_factor(model,
  factor = 1,
  color_by = "mass_category", 
  dot_size = 1.5,
  scale = TRUE, legend = FALSE
) + scale_color_manual(values=colors) + scale_fill_manual(values=colors)
```

We can now plot weights of factor 1 to determine the most important
species that impact factor 1.

```{r}
plot_weights(model,
  view = "metagenomic_assembly",
  factor = 1,
  nfeatures = 10,
  scale = T
)
```

_Mycoplasma_ genus stands out, and it has high positive weight, which
suggests that it is an abundant species in salmons with positive Factor 1
values. Most high positive numbers are located in treatment group and are salmons
from the light mass category.


```{r}
plot_top_weights(model, 
  view = "metagenomic_assembly",
  factor = 1, 
  nfeatures = 10,
  scale = T, 
  abs = T
)
```

Strangely, family _Mycoplsmataceae_ has very low weight.

```{r}
species <- c("Mycoplasma")

for (i in species) {
  
  p <- plot_factor(model,
    factor = 1,
    dot_size = 2.5,
    color_by = i
  ) + scale_colour_gradientn(colours = terrain.colors(10)) # change color scale
  
  print(p)
  
}
```

Three samples have high abundances of _Mycoplasma_ as well as one sample in
control.

## IntegratedLearner

### Data preparation

```{r}
# Get colData
mae_coldata <- colData(mae_sub)

# Create feature dataframe for IntegratedLearner
metabolomics_df <- mae_sub[[1]] |> assay("log10") |> as.data.frame()
metagenomics_df <- mae_sub[[2]] |> assay("clr") |> as.data.frame()

# Replace "sample" names to animal accession numbers
names(metabolomics_df) <- colData(mae[[1]])[, "animal"]
names(metagenomics_df) <- colData(mae[[2]])[, "animal"]

# Join feature tables together
feature_table <- rbind(metagenomics_df, metabolomics_df)

# Sanity check: are columns from colData the same as rownames of feature table
all(colnames(metagenomics_df) == rownames(colData(mae_sub))) # TRUE
all(colnames(metabolomics_df) == rownames(colData(mae_sub))) # TRUE
```

We also need to retain only features with non-zero variance

```{r feature-table-remove-zero-variance}
# Transpose feature table for subsequent filtering
feature_table_t <- as.data.frame(t(feature_table))

# Filter out out near-zero-variance features
nzv <- nearZeroVar(feature_table_t)
features_filtered <- feature_table_t[, -nzv]
features_table <- as.data.frame(t(features_filtered))
```


```{r}
# Y column for sample_metadata
Y <- as.numeric(factor(mae_coldata$mass_category))
# Change all 1s to 0 and all 2s to 1
Y <- ifelse(Y == 1, 0, ifelse(Y == 2, 1, Y))

# Create sample_metadata dataframe for IntegratedLearner
sample_metadata <- data.frame(
  Y = Y,
  subjectID = colnames(metabolomics_df)
)
rownames(sample_metadata) <- colnames(metabolomics_df)

# Create feature metadata dataframe for metagenomics
feature_metadata_metagenomics <- data.frame(
  featureID = rownames(metagenomics_df),
  featureType = "species"
)
rownames(feature_metadata_metagenomics) <- feature_metadata_metagenomics$featureID

# Create feature metadata dataframe for metabolomics
feature_metadata_metabolomics <- data.frame(
  featureID = rownames(metabolomics_df),
  featureType = "metabolites"
)
rownames(feature_metadata_metabolomics) <- feature_metadata_metabolomics$featureID

# Create feature_metadata dataframe for IntegratedLearner
feature_metadata <- rbind(feature_metadata_metagenomics, feature_metadata_metabolomics)

# Transform featureID into factors
feature_metadata$featureID <- as.factor(feature_metadata$featureID)
```

```{r}
# Mass category distribution (1: heavy, 2: light)
table(sample_metadata$Y)
```

```{r}
# Sanity check
all(rownames(feature_table) == rownames(feature_metadata)) # TRUE
all(colnames(feature_table) == rownames(sample_metadata)) # TRUE
```

### Random forest algorithm

```{r}
set.seed(423)
# Split dataframes into train and validation dataframes
feature_table_sample <- sample(
  c(TRUE, FALSE), ncol(feature_table), replace = TRUE, prob = c(0.8, 0.2))
feature_table_train <- feature_table[, feature_table_sample]
feature_table_valid <- feature_table[, !feature_table_sample]

# feature_metadata (probably not required)
# feature_metadata_train <- data.frame(feature_metadata)
# feature_metadata_valid <- data.frame(feature_metadata)

# sample_metadata
sample_metadata_train <- sample_metadata[colnames(feature_table_train), ]
sample_metadata_valid <- sample_metadata[colnames(feature_table_valid), ]

# Sanity check
all(rownames(sample_metadata_train) == colnames(feature_table_train)) # TRUE
all(rownames(sample_metadata_valid) == colnames(feature_table_valid)) # TRUE
```

```{r}
# Random forest fit
rf_fit <- IntegratedLearner(feature_table = feature_table_train,
                               sample_metadata = sample_metadata_train,
                               feature_metadata = feature_metadata,
                               feature_table_valid = feature_table_valid,
                               sample_metadata_valid = sample_metadata_valid,
                               folds = 10,
                               base_learner = "SL.randomForest",
                               meta_learner = "SL.nnls.auc",
                               verbose = TRUE,
                               family = binomial())
```

```{r}
# Visualization of AUC curves to predict heavy vs. light mass categories
plot.obj <- IntegratedLearner:::plot.learner(rf_fit)
```

When using stacked approach or metabolites, the area-under-curve is very high: 0.98.

#### Trial time points

There are two trial time points: 0 and 60 days.

After encoding 1 is 60 days, and 0 is 0 days.

```{r}
# Y column for sample_metadata
Y <- as.numeric(factor(time_merged_coldata$trial.timepoint))
# Change all 1s to 0 and all 2s to 1
Y <- ifelse(Y == 1, 0, ifelse(Y == 2, 1, Y))

# Create sample_metadata dataframe for IntegratedLearner
sample_metadata <- data.frame(
  Y = Y,
  subjectID = colnames(metabolomics_df)
)
rownames(sample_metadata) <- colnames(metabolomics_df)

# Split sample_metadata into train and validation dataframes
# feature_table and feature_metadata remain the same
sample_metadata_train <- sample_metadata[colnames(feature_table_train), ]
sample_metadata_valid <- sample_metadata[colnames(feature_table_valid), ]

# Sanity check
all(rownames(sample_metadata_train) == colnames(feature_table_train)) # TRUE
all(rownames(sample_metadata_valid) == colnames(feature_table_valid)) # TRUE
```


```{r}
# Random forest fit
rf_fit <- IntegratedLearner:::IntegratedLearner(feature_table = feature_table_train,
                               sample_metadata = sample_metadata_train,
                               feature_metadata = feature_metadata,
                               feature_table_valid = feature_table_valid,
                               sample_metadata_valid = sample_metadata_valid,
                               folds = 10,
                               base_learner = "SL.randomForest",
                               meta_learner = "SL.nnls.auc",
                               verbose = TRUE,
                               family = binomial())
```

```{r}
# Visualization (trial time points)
plot.obj <- IntegratedLearner:::plot.learner(rf_fit)
```

Trial time points can also be predicted with high accuracy.

#### Treatment group

Finally, we can test whether predictions of treatment vs. control can be made.

After encoding, control is 0, and treatment is 1.

```{r}
# Y column for sample_metadata
Y <- as.numeric(factor(mae_coldata$treatment_group))

# Change all 1s to 0 and all 2s to 1
Y <- ifelse(Y == 1, 0, ifelse(Y == 2, 1, Y))

# Create sample_metadata dataframe for IntegratedLearner
sample_metadata <- data.frame(
  Y = Y,
  subjectID = colnames(metabolomics_df)
)
rownames(sample_metadata) <- colnames(metabolomics_df)

# Split sample_metadata into train and validation dataframes
# feature_table and feature_metadata remain the same
sample_metadata_train <- sample_metadata[colnames(feature_table_train), ]
sample_metadata_valid <- sample_metadata[colnames(feature_table_valid), ]

# Sanity check
all(rownames(sample_metadata_train) == colnames(feature_table_train)) # TRUE
all(rownames(sample_metadata_valid) == colnames(feature_table_valid)) # TRUE
```

```{r}
# Random forest fit for treatment vs. control
rf_fit <- IntegratedLearner:::IntegratedLearner(feature_table = feature_table_train,
                               sample_metadata = sample_metadata_train,
                               feature_metadata = feature_metadata,
                               feature_table_valid = feature_table_valid,
                               sample_metadata_valid = sample_metadata_valid,
                               folds = 10,
                               base_learner = "SL.randomForest",
                               meta_learner = "SL.nnls.auc",
                               verbose = TRUE,
                               family = binomial())
```

```{r}
# Visualization (treatment vs. control)
plot.obj <- IntegratedLearner:::plot.learner(rf_fit)
```

Predictions for training data of random forest algorithm.

```{r}
rf_fit$yhat.train
```


Similarly, metabolites seem to be promising in predicting treatment versus control
groups and are comparable to an algorthimg from early fusion famility with
stacked architecture (see https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8921642/).

## Intermediate fusion

We can also approach this data with an intermediate fusion algorithm. In this
section, we will:

1. Apply intermediate fusion to predict treatment versus control
2. Combine the predictions from intermediate fusion with those from intermediate fusion
early fusion with Random Forest we performed before
3. Compare the performance of the intermediate fusion approach to early fusions with an AUC plot
4. Visualize the top 20 features of the metabolomic and metagenomic layers
by using logarithmic fold change (LFC)

Clearly, the predictions of treatment or control are of no interest in this case.
However, one can be interested in which features of each layer are the most important in order to distinguish control from treatment.

Code adapted from Chapter 15 of [Orchestrating Microbiome Analysis book](https://microbiome.github.io/OMA/docs/devel/pages/IntegratedLearner.html).

```{r intermediate_fusion}
##############################
# Prepare data for multiview #
##############################

# Separate omics layers
feature_metadata$featureType <- as.factor(feature_metadata$featureType)
name_layers <- levels(feature_metadata$featureType)

# Define a list
dataList <- vector("list", length = length(name_layers))
names(dataList) <- name_layers
table(feature_metadata$featureType)

# Select metabolites and species indices
metabolites_ind <- which(feature_metadata$featureType == "metabolites")
species_ind <- which(feature_metadata$featureType == "species")

# Split metabolites and species into two separate list elements
dataList[[1]] <- t(feature_table[metabolites_ind, ])
dataList[[2]] <- t(feature_table[species_ind, ])

# Extract y and X's
dataList <- lapply(dataList, as.matrix)
dataList <- lapply(dataList, scale)

# Remove missing values in columns of metabolomic matrix
dataList$metabolites <- dataList$metabolites[, !colSums(is.na(dataList$metabolites))]

# Set response variable Y to control vs. treatment
# Control: 0
# Treatment: 1
Y <- numeric_treatment_groups

########################
# Run cross-validation #
########################

set.seed(1234)
library(multiview)
library(glmnet)

cvfit <- cv.multiview(dataList, Y, family = binomial(), alpha = 0.5)
DD <- as.data.frame(as.matrix(coef_ordered(cvfit, s="lambda.min", alpha = 0.5)))
DD$standardized_coef <- as.numeric(DD$standardized_coef)
DD$coef <- as.numeric(DD$coef)
```

### Visualization

We will now compare the prediction performance of intermediate fusion with that of
early fusion.

```{r}
intermediate_pred <- stats:::predict(cvfit, newx = dataList, s = "lambda.min", alpha = 0.5, type = "response")

# Select only salmon IDs that are present in both predictions
row_names_select <- rownames(rf_fit$X_train_layers$metabolites)
intermediate_pred <- intermediate_pred[row_names_select, , drop = FALSE]

# Combine early fusion and intermediate fusion predictions
yhat.train <- cbind(rf_fit$yhat.train, coop_pred)

# Set column name to distinguish predictions algorithms
colnames(yhat.train) <- c(colnames(rf_fit$yhat.train), "intermediate fusion")

# Fetch only rows that are present in prediction's dataframe
Y <- colData(mae_sub)[row_names_select, ]
# Encode treatment and control for predictions
Y <- Y[, "treatment_group"]
Y <- ifelse(Y == "control", 0, 1)

# Extract ROC plot data
list.ROC <- vector("list", length = ncol(yhat.train))
names(list.ROC) <- colnames(yhat.train)

library(ROCR)
for (k in 1:length(list.ROC)){
  preds <- yhat.train[ ,k]
  pred <- prediction(preds, Y)
  AUC <- round(performance(pred, "auc")@y.values[[1]], 2)
  perf <- performance(pred, "sens", "spec")
  list.ROC[[k]] <- data.frame(sensitivity = slot(perf, "y.values")[[1]],
                            specificity = 1 - slot(perf, "x.values")[[1]],
                            AUC = AUC,
                            layer = names(list.ROC)[k])
}


# Combine ROC lists into a dataframe
ROC_table <- do.call("rbind", list.ROC)
```


```{r intermediate_fusion_visualization}
# Prepare data for plotting
plot_data <- ROC_table
plot_data$displayItem <- paste(plot_data$layer, " AUC = ", plot_data$AUC, sep="")
plot_data$displayItem <- factor(plot_data$displayItem,
                                    levels = unique(plot_data$displayItem))

# ROC curves
p <- ggplot(plot_data,
            aes(x = specificity,
            y = sensitivity,
            group = displayItem)) +
  geom_line(aes(x = specificity,y = sensitivity,color = displayItem)) +
  theme(legend.position = "bottom",
        legend.background=element_blank(),
        legend.box.background=element_rect(colour = "black")) +
  theme_bw() +
  xlab("False Positive Rate") +
  ylab("True Positive Rate") +
  theme(legend.position = "right", legend.direction = "vertical") +
  labs(color = '')

# Print
print(p)
```

Intermediate fusion is as efficient as the stacked early fusion of a single
metabolomic layer in distinguishing between control and treatment. However,
now we can visualize the most important features for this differentiation.

```{r intermediate_fusion_top20_features}
#| fig-width: 8
#| fig-height: 10
# Only plot top 20 features
DD <- DD %>%
  group_by(view) %>%
  top_n(n = 20, wt = abs(standardized_coef))

# Visualization
library(forcats)

p <- DD %>%
  mutate(view_col = fct_reorder(view_col, standardized_coef)) %>%
  ggplot(aes(x = view_col, y = standardized_coef, fill = view, width = 0.75)) +
  geom_bar(stat = "identity", show.legend = FALSE, width = 1) +
  coord_flip() +
  facet_wrap(~ view, scales = 'free_y', nrow = 2) +
  ylab('Standardized LFC') +
  xlab('') +
  ggtitle('IBD-associated multi-omics features') +
  theme_bw() + theme(strip.background  = element_blank(),
                     panel.grid.major = element_line(colour = "grey80"),
                     panel.border = element_blank(),
                     axis.ticks = element_line(size = 0),
                     panel.grid.minor.y = element_blank(),
                     panel.grid.major.y = element_blank())
p
```


### Bart machine algorithm

#### host.gutted.mass

For bart machine algorithm we are using full datasets, and the response
variable is continuous: `host.gutted.mass`.


```{r}
# Y column for sample_metadata
# Create sample_metadata dataframe for IntegratedLearner
Y <- mae_coldata$host.gutted.mass

sample_metadata_gutted_weight <- data.frame(
  Y = Y,
  subjectID = colnames(metabolomics_df)
)
rownames(sample_metadata_gutted_weight) <- colnames(metabolomics_df)
```


```{r}
# predict() function is conflicting with one of bartMachine algorithms
# so we need to unload it from namespace
unloadNamespace("MOFA2")

# bartMachine algorithm to predict host.gutted.weight
bart_fit <- IntegratedLearner(feature_table = feature_table,
                              sample_metadata = sample_metadata_gutted_weight,
                              feature_metadata = feature_metadata,
                              folds = 17,
                              base_learner = "SL.BART",
                              meta_learner = "SL.nnls.auc",
                              family = gaussian())
# Visualization
plot.obj <- IntegratedLearner:::plot.learner(bart_fit)
```


```{r}
# Generate credible intervals
# Requires longitudinal data for extracting very important features
bart_weights <- bart_fit$weights

bart_dataX <- bart_fit$X_train_layers
bart_dataY <- bart_fit$Y_train

bart_post.samples <- vector("list", length(bart_weights))
names(bart_post.samples) <- names(bart_dataX)

# Is not serialized when using binomial family
for (i in seq_along(bart_post.samples)) {
  bart_post.samples[[i]] <- bart_machine_get_posterior(bart_fit$model_fits$model_layers[[i]],
                                                       bart_dataX[[i]])$y_hat_posterior_samples
}

bart_weighted.post.samples <- Reduce("+", Map("*", bart_post.samples, bart_weights))
rownames(bart_weighted.post.samples) <- rownames(bart_dataX[[1]])
```

```{r}
#| fig-width: 10
#| fig-height: 7

# Get a random samples of posterior weights
post_samples <-bart_weighted.post.samples[sample(nrow(bart_weighted.post.samples), size=50), ]

# Show credible intervals for hosted.gut.weight
temp <- caterplot(t(post_samples),
          horizontal = FALSE, add = FALSE)
points(bart_dataY[temp])
title(main ="", xlab = "Observations", ylab = "Host gutted mass (in gramms)",
       line = NA, outer = FALSE)
```

We can observe in the figure above that heavy and light salmons are clearly
separated, and credible intervals are similar to each other.

```{r}
### Find most important features ###
omicsEye_theme <- function() {
# set default text format based on categorical and length
  angle = 45
  hjust = 1
  size = 6
  return (ggplot2::theme_bw() + ggplot2::theme(
    axis.text.x = ggplot2::element_text(size = 8, vjust = 1, hjust = hjust, angle = angle),
    axis.text.y = ggplot2::element_text(size = 8, hjust = 1),
    axis.title = ggplot2::element_text(size = 10),
    plot.title = ggplot2::element_text(size = 10),
    plot.subtitle = ggplot2::element_text(size = 8),
    legend.title = ggplot2::element_text(size = 6, face = 'bold'),
    legend.text = ggplot2::element_text(size = 7),
    axis.line = ggplot2::element_line(colour = 'black', size = .25),
    ggplot2::element_line(colour = 'black', size = .25),
    axis.line.x = ggplot2::element_line(colour = 'black', size = .25),
    axis.line.y = ggplot2::element_line(colour = 'black', size = .25),
    panel.border = ggplot2::element_blank(),
    panel.grid.major = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank())
  )
}

myColtmp <- c("cornflowerblue","darkcyan","orchid4",
            "brown","goldenrod4","mistyrose4","darkgreen","purple")


VIMP_stack <- cbind.data.frame(bart_fit$weights)

colnames(VIMP_stack) <- c("mean")
VIMP_stack$sd <- NA
VIMP_stack$type <- "stack"


# Microbiome
qq <- bartMachine::investigate_var_importance(bart_fit$model_fits$model_layers$species, plot = FALSE)

VIMP_microbiome <- cbind.data.frame(qq$avg_var_props, qq$sd_var_props)
colnames(VIMP_microbiome) <- c("mean", "sd")
VIMP_microbiome$type <- "species"

# Metabolomics
qq <- bartMachine::investigate_var_importance(bart_fit$model_fits$model_layers$metabolites, plot = FALSE)

VIMP_metabolites <- cbind.data.frame(qq$avg_var_props, qq$sd_var_props)
colnames(VIMP_metabolites )<- c("mean", "sd")
VIMP_metabolites$type <- "metabolites"

VIMP <- as.data.frame(rbind.data.frame(VIMP_stack,
                                     VIMP_microbiome[1:20,],
                                     VIMP_metabolites[1:20,]))


VIMP <- rownames_to_column(VIMP, "ID")


p4 <- VIMP %>%
  filter(type == "stack") %>%
  arrange(desc(mean))  %>%
  ggplot(aes(y = mean, x = reorder(ID,-mean))) +
  geom_bar(stat = "identity", fill = 'darkseagreen') +
  theme_bw() +
  #coord_flip() +
  omicsEye_theme() +
  ylab("Layer Weights") +
  xlab("")


p5 <- VIMP %>%
  filter(type %in% c('species', 'metabolites')) %>%
  arrange(mean) %>%
  mutate(ID = str_replace_all(ID, fixed("_"), " ")) %>%
  mutate(type = factor(type,
                       levels = c('species', 'metabolites'),
                       labels = c('species', 'metabolites'))) %>%
  ggplot(aes(reorder(ID, -mean), mean, fill = type)) +
  facet_wrap(.~ type, scale = 'free') +
  geom_bar(stat = "identity", fill = "lightsalmon") +
  geom_errorbar(aes(ymin=ifelse(mean-sd>0,mean-sd,0), ymax=mean+sd), width=.2, position=position_dodge(.9)) +
  theme_bw() +
  coord_flip() +
  omicsEye_theme() +
  theme (strip.background = element_blank()) +
  ylab('Inclusion proportion') +
  xlab('')


plot_grid(p4,
             ncol = 1,
             labels = c('Estimated IntegratedLearner layer weights'),
             label_size = 8, vjust = 0.1)+
  theme(plot.margin = unit(c(0.5,0.5,0.5,0.5), "cm"))
```

```{r}
plot_grid(p5,
             ncol = 1,
             labels = c("Top 20 features of microbiome and metabolites layers"),
             label_size = 8, vjust = 0.1)+
  theme(plot.margin = unit(c(0.5,0.5,0.5,0.5), "cm"))
```


## XGBoost algorithm

We can also test another algorithm, namely XGboos as an alternative to
Random Forest.

### Host gutted weight

First, we will use try to predicted host gutted weight.

```{r}
# sample_metadata
sample_metadata_gutted_weight_train <- sample_metadata_gutted_weight[colnames(feature_table_train), ]
sample_metadata_gutted_weight_valid <- sample_metadata_gutted_weight[colnames(feature_table_valid), ]

# Sanity check
all(rownames(sample_metadata_gutted_weight_train) == colnames(feature_table_train)) # TRUE
all(rownames(sample_metadata_gutted_weight_valid) == colnames(feature_table_valid)) # TRUE

# Run xgboost algorithm (with linear model meta-learner)
xgboost <- IntegratedLearner(
  feature_table = feature_table_train,
  sample_metadata = sample_metadata_gutted_weight_train,
  feature_metadata = feature_metadata,
  feature_table_valid = feature_table_valid,
  sample_metadata_valid = sample_metadata_gutted_weight_valid,
  folds = 10,
  base_learner = "SL.xgboost",
  meta_learner = "SL.lm", # Use linear model as meta-learner instead of non-negative
  # least squares
  verbose = TRUE,
  family = gaussian()
)
```
```{r}
# Visualize xgboos algorithm AUC curves
plot.obj  <- IntegratedLearner:::plot.learner(xgboost)
```


```{r}
#' Test which algorithm outputs the highest R^2 metrics for Concatenated model
#' using gutted.host.weight response variable
#' @param algorithm base_learner algorithm
# Function to test algorithms (with linear model meta-learner)
test_model <- function(algorithm) {
  model <- IntegratedLearner(
  feature_table = feature_table_train,
  sample_metadata = sample_metadata_gutted_weight_train,
  feature_metadata = feature_metadata,
  feature_table_valid = feature_table_valid,
  sample_metadata_valid = sample_metadata_gutted_weight_valid,
  folds = 10,
  base_learner = algorithm,
  meta_learner = "SL.lm", # Use linear model as meta-learner instead of non-negative
  # least squares
  verbose = TRUE,
  family = gaussian()
  )

  return (model$R2.test[["stacked"]])
}

# Results
results <- list()
algorithms <- c(
  "SL.bartMachine",
  "SL.glmnet",
  "SL.svm" # Support Vector Machines
)

for (algorithm in algorithms) {
  r_squared <- test_model(algorithm)
  results[[algorithm]] <- r_squared
}

print(results)
```

`glmnet` algorithm has the highest AUC with stacked approach.


### Other algorithms

```{r}
# Run xgboost algorithm
# (fails with errors) # see code here https://rdrr.io/cran/SuperLearner/src/R/SuperLearner.R
xgboost <- IntegratedLearner(
  feature_table = feature_table_train,
  sample_metadata = sample_metadata_gutted_weight_train,
  feature_metadata = feature_metadata,
  feature_table_valid = feature_table_valid,
  sample_metadata_valid = sample_metadata_gutted_weight_valid,
  folds = 5,
  base_learner = "SL.xgboost",
  meta_learner = "SL.nnls.auc",
  verbose = TRUE,
  family = gaussian()
)
```


## Conclusions

The present case study has demonstrated how easy and fast it is to
download large dataset and transform the data into a MultiAssayExperiment, which
in turn gives the researchers access to an extensive plethora of downstream
tools, such mia and MOFA2 that can be used to pre-process and visualize the
multi-omics data.

```{r session_info}
sessionInfo()
```

