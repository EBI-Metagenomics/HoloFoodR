---
title: "ECCB Paper HoloFood Salmon - MOFA2 Analysis"
date: "`r Sys.Date()`"
package: HoloFoodR
output:
    BiocStyle::html_document:
        fig_height: 7
        fig_width: 10
        toc: yes
        toc_depth: 2
        number_sections: true
vignette: >
    %\VignetteIndexEntry{mia}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
library(knitr)
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>",
    cache = TRUE
)
```

```{r setup}
# List of packages that we need
packages <- c(
    "ggplot2", "knitr", "mia", "dplyr", "miaViz", "MOFA2",  "patchwork", "reticulate",
    "MGnifyR", "reshape2", "GGally", "IntegratedLearner", "SuperLearner",
    "bartMachine", "mcmcplots", "tidyverse", "UpSetR", "shadowtext", "ComplexHeatmap",
    "stringr", "cowplot", "caret", "scater"
    )

# Get packages that are already installed installed
packages_already_installed <- packages[ packages %in% installed.packages() ]

# Get packages that need to be installed
packages_need_to_install <- setdiff( packages, packages_already_installed )

# Loads BiocManager into the session. Install it if it not already installed.
if( !require("BiocManager") ){
    install.packages("BiocManager")
    library("BiocManager")
}

# If there are packages that need to be installed, installs them with BiocManager
# Updates old packages.
if( length(packages_need_to_install) > 0 ) {
   install(packages_need_to_install, ask = FALSE)
}

# Load all packages into session. Stop if there are packages that were not
# successfully loaded
pkgs_not_loaded <- !sapply(packages, require, character.only = TRUE)
pkgs_not_loaded <- names(pkgs_not_loaded)[ pkgs_not_loaded ]
if( length(pkgs_not_loaded) > 0 ){
    stop("Error in loading the following packages into the session: '", paste0(pkgs_not_loaded, collapse = "', '"), "'")
}
```

```{r}
# Provide Java with RAM
options(java.parameters = "-Xmx8g")
```

## Import data

### Retrieve HoloFood data

Firstly, we have to query the HoloFood database to retrieve the salmon accession
numbers.

```{r get_animals}
# Get salmon samples
salmons <- HoloFoodR::doQuery("animals", system = "salmon", use.cache = TRUE)

# Get only salmon metagenomic and fatty acid data
salmons <- salmons |>
  filter(fatty_acids == TRUE & metagenomic_amplicon == TRUE)

colnames(salmons)
```

Next, we can retrieve the data associated with each salmon.

```{r get_animal_data}
# Get salmon data
salmon_data <- HoloFoodR::getData(
  accession.type = "animals",
  accession = salmons[["accession"]],
  use.cache = TRUE
)
```

```{r get_salmon_samples1}
# Get salmon samples
salmon_samples <- salmon_data[["samples"]]

# Get sample IDs
salmon_sample_ids <- unique(salmon_samples[["accession"]])

head(salmon_sample_ids)
```

Finally, we can retrieve the data from each sample of each sample (for instance,
metagenomic, metabolomic, transcriptomic, etc.) and store the result in a
MultiAssayExperiment object.

```{r get_salmon_mae}
# Get salmon <- experiments as MAE object
mae <- HoloFoodR::getResult(
  salmon_sample_ids,
  use.cache = TRUE
)

# Save salmon MAE
saveRDS(object = mae, file = "../inst/extdata/salmon_mae_without_mgnify.RDS")

# Rename FATTY ACIDS MG to more readable format
names(mae)[1] <- tolower(gsub(" ", "_", names(mae)[1]))

# Show available salmon experiments
experiments(mae)
```

### Fetch metagenomic data from MGnify

HoloFood database does not include the data for metagenomic assemblies, which
can be retrieved from the [MGnify portal](https://www.ebi.ac.uk/metagenomics).

```{r get_metagenomic_samples}
# Create MGnify object
mg <- MgnifyClient(
  useCache = TRUE,
  cacheDir = ".MGnifyR_cache"
)

# Select only metagenomic assembly samples types
metagenomic_salmon_samples <- salmon_samples[
  salmon_samples[["sample_type"]] == "metagenomic_amplicon",
]

# Search for sample IDs in MGnify database
salmon_analysis_ids <- searchAnalysis(
  mg,
  type = "samples",
  metagenomic_salmon_samples[["accession"]]
)
```

```{r get_metagenomic}
# Get metagenomic taxonomic data for salmon from MGnify
tse <- MGnifyR::getResult(
  x = mg,
  accession = salmon_analysis_ids,
  get.func = FALSE
)

# Save salmon metagenomic TSE
saveRDS(object = tse, file = "../inst/extdata/salmon_metagenomic_tse.RDS")
```

Data fetched from MGnify has MGnify-specific identifiers. We have to first
rename samples with HoloFood specific ID and then add the data to
MultiAssayExperiment combining all the data.


```{r add_metagenomic_data}
# Read in salmon metagenomic TSE object
tse <- readRDS(file = "../inst/extdata/salmon_metagenomic_tse.RDS")

.add_MGnify <- function(
        mae, tse, holofood.id = "sample_biosample",
        exp.name = "metagenomic_amplicon", new.exp = "metagenomic",
        replace = TRUE){
    # Rename columns based on HoloFood ID
    colnames(tse) <- colData(tse)[[holofood.id]]

    # Merge add MGnify metagenomic data to the existing metagenomic_amplicon
    # experiment. Get the experiment from HoloFood data.
    tse2 <- mae[[exp.name]]

    # Combine sample metadata
    cd1 <- as.data.frame(colData(tse))
    cd2 <- as.data.frame(colData(tse2))
    cd <- merge(
        cd1, cd2,
        by.x = holofood.id,
        by.y = "accession",
        all.x = TRUE
    )
    rownames(cd) <- cd[[holofood.id]]

    # Now order colData to ensure that order is correct
    cd <- cd[colnames(tse), ]

    # Add it to TreeSE
    colData(tse) <- DataFrame(cd, check.names = FALSE)

    # Rename to match HoloFood
    colnames(tse) <- colData(tse)[[holofood.id]]

    # Now order the data based on TreeSE in MAE
    # First take those columns that can be found
    mae[[exp.name]] <- mae[[exp.name]][
        , colnames(mae[[exp.name]]) %in% colnames(tse) ]

    # Then order
    tse <- tse[, match(colnames(mae[[exp.name]]), colnames(tse))]
    # And add to MAE in place of old experiment
    if( replace ){
        mae[[exp.name]] <- tse
    } else{
        # Get sample map
        sample_map <- sampleMap(mae)
        # Get samples that are matching with those one that are being added
        add_sample_map <- sample_map[
            match(colnames(tse), sample_map[["colname"]]), ]
        # Rename the experiment
        add_sample_map[["assay"]] <- new.exp
        # Add to sample map'
        sample_map <- rbind(sample_map, add_sample_map)
        # Create MAE
        tse <- ExperimentList(temp = tse)
        names(tse) <- new.exp

        exp_list <- c(experiments(mae), tse)
        mae <- MultiAssayExperiment(
            exp_list, colData = colData(mae), sampleMap = sample_map)
    }
    return(mae)
}

mae <- .add_MGnify(mae, tse)

# Save to merged MAE object to RDS
saveRDS(object = mae, file = "../inst/extdata/salmon_mae.RDS")
```

## Data preprocess

Now we can pre-process data and prepared it for subsequent analyses.

```{r load_data}
path <- system.file("extdata", "salmon_mae.RDS", package = "HoloFoodR")
#salmon_mae <- readRDS(path)
# mae <- readRDS(path)
mae <- readRDS("../inst/extdata/salmon_mae.RDS")

# Fetch only experiments that we need
mae <- mae[, , c("fatty_acids_mg", "metagenomic_amplicon")]
```

```{r preprocess}
# From metabolomic data, remove organ-fatty acids row as it only contains a
# string value "muscle"
tse <- mae[[1]]
tse <- tse[!(rowData(tse)[["marker.name"]] %in% c("Organ-fatty acids")), ]
mae[[1]] <- tse

# Transform matrices to numeric. Some values are "< 0.01"
# If a number is < 0.01, assume it to be 0
assay <- assay(mae[[1]], "counts")
assay[ assay == "<0.01" ] <- 0
assay <- apply(assay, c(1, 2), function(x) as.numeric(gsub(",", ".", x)))

# Reassign assay back to MAE
assay(mae[[1]], "counts") <- assay

# From metagenomic data, remove those rows that do not have taxonomy info
not_empty <- !apply(rowData(mae[[2]]), 1, function(x) all(is.na(x)))
mae[[2]] <- mae[[2]][ not_empty, ]
```

For demonstration purposes, we will focus on investigating two experiments
(`fatty_acids_mg` and `metagenomic_amplicon`) within the trial A performed by
the HoloFood consortium. This trial the health effects of fermented seaweed added
to the diet of salmons.

```{r preprocess2}
# Filter MAE object to include only Trial A
mae <- mae[ , colData(mae)[["Trial code"]] == "SA", ]
mae
```


Before proceeding we keep the modified version of MultiAssayExperiment object
intact and only modify its copy.

```{r save_original_mae}
mae_sub <- mae # Keep original MAE intact
```


```{r}
# Take those samples that can be found from both experiments
mae_sub <- intersectColumns(mae_sub)
```

Next, we transform the metagenomic and metabolomic data  to normalize the data,
especially compositional data, such as metagenomic counts.

We log-transform fatty acid assay to approximate it to normal distribution.

```{r transformation_fatty_acids}
# Transform fatty acids in mg with log10
mae_sub[["fatty_acids_mg"]] <- transformAssay(
    mae_sub[[1]],
    assay.type = "counts",
    MARGIN = "samples",
    method = "log10",
    pseudocount = TRUE
)
```

```{r transformation_metagenomics}
# Transform microbiome with centered log-ratio method
mae_sub[["metagenomic_amplicon"]] <- transformAssay(
    mae_sub[["metagenomic_amplicon"]], method = "relabundance")
mae_sub[["metagenomic_amplicon"]] <- transformAssay(
    mae_sub[["metagenomic_amplicon"]], assay.type = "relabundance", method = "clr", pseudocount = TRUE)
```

Next, we can agglomerate features by prevalence to reduce the number of
low-abundant species.


```{r}
x <- agglomerateByRank((mae_sub[[2]]), "Genus", na.rm = TRUE) |> assay("counts")
x["Ammopiptanthus", ] |> hist(
  xlab="Number of reads",
  breaks=10,
  freq = FALSE,
  main = "Ammopiptanthus")
```

```{r}
# Remove taxonomy_unparsed column from rowData of metagenomic_amplicon
rowData(mae_sub[[2]]) <- rowData(mae_sub[[2]])[, 1:(length(rowData(mae_sub[[2]])) - 1)]

prevalence <- getPrevalence(mae_sub[[2]],
                        rank = "Genus",
                        assay.type = "relabundance",
                        na.rm = TRUE,
                        sort = TRUE,
                        detection = 0.001)

# Exclude microbes with 0 prevalence
prevalence <- prevalence[prevalence != 0]

# Sort prevalence in decreasing order
sort(prevalence, decreasing = T) |> head(90)
```

```{r}
prevalence |> hist(breaks = 5)
```


```{r}
# Manually compute prevalence
compute_prev <- function(genus) {
  agglomerated_genus <- agglomerateByRank(mae_sub[[2]],
    "Genus",
    assay.type = "relabundance",
    na.rm = TRUE
  )
  assay <- assay(agglomerated_genus, "relabundance")[genus, ]
  logical_ind <- assay(agglomerated_genus, "relabundance")[genus, ] > 0.001


  prev <- length(assay[logical_ind]) / dim(mae_sub[[2]])[2]
  return(prev)
}

compute_prev("Ammopiptanthus")
```

```{r}
# Compare two sets of animal samples in order to add the treatment concentration
# column to metagenomic data
setdiff(colData(mae_sub)$animal, colData(mae_sub[[2]])$animal) # No difference

# We then can simply add treatment_concentration column to metagenomic data
colData(mae_sub[["metagenomic_amplicon"]])$treatment_concentration <-
  colData(mae_sub)$`Treatment concentration`

# Add treatment_group (control vs. treatment) to metagenomic data
metagenomic_data <- colData(mae_sub[["metagenomic_amplicon"]])
metagenomic_data$treatment_group <-
  ifelse(metagenomic_data$treatment_concentration == 0, "control", "treatment")
colData(mae_sub[["metagenomic_amplicon"]]) <- metagenomic_data
```
### Agglomerate by genus and sort by the number of reads.

When using `onRankOnly = TRUE` genera become separate separate entities in
`rowData`.

The selection of the most prevalent genera is a hard topic. I have noticed that
a flowering plant genus _Ammopiptanthus_ appears in the data. However, since
it is part of the phylum Viridiplantae, I believe it is a false positive as
_Viridiplantae_ includes green algae (see https://www-ncbi-nlm-nih-gov.ezproxy.utu.fi/books/NBK579936/).

We a reasonable prevalence of 20%, and relative abundance detection threshold
of 0.02%, only bacteria species remain.

```{r}
# Agglomerate by prevalence by genus
altExp(mae_sub[["metagenomic_amplicon"]], "prev_genus") <- agglomerateByPrevalence(mae_sub[["metagenomic_amplicon"]],
    assay.type = "relabundance",
    rank = "Genus",
    na.rm = TRUE,
    agg.na.rm = TRUE,
    prevalence = 20 / 100,
    detection = 0.002
  )

altExp(mae_sub[[2]], "prev_genus")
```


```{r}
# Extract only transformed metabolomic assays
assays(mae_sub[[1]]) <- assays(mae_sub[[1]])[names(assays(mae_sub[[1]])) %in% c("log10")]

# Rename column names to make them more consistent
names(colData(mae_sub)) <- tolower(gsub(" ", "_", names(colData(mae_sub))))

# Add salmon host mass to colData
merged_coldata <- merge(x = colData(mae_sub), y = colData(mae_sub[[2]])[c("animal", "host.gutted.mass")], all.x = TRUE, by = "animal")
rownames(merged_coldata) <- merged_coldata$animal
colData(mae_sub) <- merged_coldata
```

We need to add a few columns for the subsequent data analysis steps. For instance,
we are interested in understanding the difference between heavy and light salmons
split into two groups by the median of their mass.

```{r add_salmon_mass_category}
# Add mass categories to main MAE object
# mass_median <- median(as.numeric(colData(mae_sub)[, "host.gutted.mass"]), na.rm = TRUE)
# colData(mae_sub)["mass_category"] <- ifelse(
#   as.numeric(colData(mae_sub)[, "host.gutted.mass"]) > mass_median, "heavy", "light"
# )
#
# # Add mass categories to alternative experiment with agglomerated by prevalence
# # metagenomic data
# mass_median <- median(as.numeric(colData(altExp(mae_sub[[2]]))[, "host.gutted.mass"]), na.rm = TRUE)
# colData(altExp(mae_sub[[2]], "prev_genus"))["mass_category"] <- ifelse(
#   as.numeric(colData(altExp(mae_sub[[2]], "prev_genus"))[, "host.gutted.mass"]) > mass_median, "heavy", "light"
# )
```

We are also interested in investigating potential differences between treatment
and control.

```{r add_treatment_group}
colData(mae_sub)["treatment_group"] <-
  ifelse(colData(mae_sub)$treatment_concentration == 0, "control", "treatment")
```

## Data exploration

```{r show_metadata2}
# Display columns of MAE object to select those of interest
colData(mae) |> names()
```

### Abundance plot

And abundance plot of centered-log-ratio transformed metagenomic species
is important for general understanding of the data. Additionally,
we also indicate "control" and "treatment" groups with colors for initial
assessment of difference between the groups.

```{r plot_abundance}
plotAbundanceDensity(altExp(mae_sub[[2]], "prev_genus"), assay.type = "clr", colour_by = "treatment_group") +
  labs(title = "Abundance plot")
```

_Mycoplasma_ has bee shown to be associated with positive health effects
(https://doi-org.ezproxy.utu.fi/10.1186/s42523-021-00096-2) and is generally
predominant in salmons (https://doi-org.ezproxy.utu.fi/10.1007/s00248-002-1011-6).

The addition of treatment does not change the weight of salmons.

## Perform cross-association analysis

Before cross-association analysis, we can filter out all features with
standard deviation equal to 0 to avoid warnings from the cross-association
function.


```{r filter_0_sd}
altExp(mae_sub[[1]], "not_sd_0") <- mae_sub[[1]][apply(assay(mae_sub[[1]], "log10"), 1, sd) != 0, ]
```


```{r cross_association_analysis}
#| fig-width: 15
#| fig-height: 15

# Perform cross-association analysis
res <- testExperimentCrossAssociation(
    mae_sub,
    experiment1 = 1,
    experiment2 = 2,
    altexp1 = "not_sd_0",
    altexp2 = "prev_genus",
    method = "kendall",
    assay.type1 = "log10",
    assay.type2 = "clr",
    mode = "matrix"
    )

# Create a heatmap and store it
plot <- Heatmap(
    res$cor,
    # Print values to cells
    cell_fun = function(j, i, x, y, width, height, fill) {
        # If the p-value is under threshold
        if( !is.na(res$p_adj[i, j]) & res$p_adj[i, j] < 0.05 ){
            # Print "X"
          grid.shadowtext(sprintf("%s", "X"), x, y, gp = gpar(fontsize = 10, col = "white"))
        }
    },
    heatmap_legend_param = list(title = "", legend_height = unit(10, "cm"))
)

draw(plot, padding = unit(c(2, 20, 2, 25), "mm"))
```

## Principal coordinate analysis (PCoA) of beta-diversity

We can perform principle coordinate analysis with multi-dimensional scaling
based on Bray-Curtis index and visualize the results with explained variances
on axes.

```{r pcoa_beta_diversity1}
# Run PCoA with multi-dimensional scaling and Bray-Curtis index
tse_pcoa <- runMDS(mae_sub[["metagenomic_amplicon"]],
                   FUN = vegan::vegdist,
                   methods = "bray",
                   assay.type = "relabundance",
                   name = "MDS_bray")

# Display dissimilarity on a plot
p <- plotReducedDim(tse_pcoa, "MDS_bray",
                    colour_by = "treatment_group")

# Calculate explained variance
e <- attr(reducedDim(tse_pcoa, "MDS_bray"), "eig")
rel_eig <- e / sum(e[e > 0])

# Add explained variance for each axis
p <- p + labs(x = paste("PCoA 1 (", round(100 * rel_eig[[1]], 1),
                        "%", ")", sep = ""),
              y = paste("PCoA 2 (", round(100 * rel_eig[[2]], 1),
                        "%", ")", sep = ""))

p
```

It seems that control and treatment groups are not dissimilar.

We can also apply different methods on the same data and visualize the
results.

```{r}
# Run NMDS on relative abundance assay with Bray-Curtis distances
tse_pcoa <- runNMDS(tse_pcoa,
               FUN = vegan::vegdist,
               method = "bray",
               assay.type = "relabundance",
               name = "NMDS_bray")

# Run MDS on clr assay with Aitchison distances
tse_pcoa <- runMDS(tse_pcoa,
              FUN = vegan::vegdist,
              method = "euclidean",
              assay.type = "clr",
              name = "MDS_aitchison")

# Run NMDS on clr assay with Euclidean distances
tse_pcoa <- runNMDS(tse_pcoa,
               FUN = vegan::vegdist,
               method = "euclidean",
               assay.type = "clr",
               name = "NMDS_aitchison")



plots <- lapply(c("MDS_bray", "MDS_aitchison",
                  "NMDS_bray", "NMDS_aitchison"),
                plotReducedDim,
                object = tse_pcoa,
                colour_by = "treatment_group")

# Generate multi-panel plot
wrap_plots(plots) +
  plot_layout(guides = "collect")
```
All four methods demonstrate that features from control and treatment are
not dissimilar.

## MOFA analysis

Multi-omic factor analysis allows us to discover latent factors that underlie
the biological differences by taking in consideration 2 or more omic assays.
To cite the original authors, "MOFA can be viewed as a statistically rigorous
generalization of (sparse) principal component analysis (PCA) to multi-omics
data".

We will use multi-group functionality and try to find the shared and exclusive
variability between two groups of salmons at day 60 (after treatment).

1. Heavy salmons that weigh more than than median
2. Light salmons that weigh less than median

Since we could not find any differentiation between salmons in control and
treatment groups, we would like to know if any of metagenomic species or fatty
acids drive the difference in salmon weight.


```{r mofa_fit}
# For MOFA, substitute metagenomic_amplicon experiment from MAE with agglomerated
# by prevalence from alternative experiment
mae_sub[[2]] <- altExp(mae_sub[[2]], "prev_genus")

# Fetch only salmons at day 60
mae_day_60 <- mae_sub[, colData(mae_sub[[2]])$trial.timepoint == 60]

# Add mass categories to mae_day_60
# This number is different from the media for the entire MAE object
# as this one was filtered to include **only** salmons at day 60
mass_median <- median(as.numeric(colData(mae_day_60)[, "host.gutted.mass"]), na.rm = TRUE)
colData(mae_day_60)["mass_category"] <- ifelse(
  as.numeric(colData(mae_day_60)[, "host.gutted.mass"]) > mass_median, "heavy", "light"
)

# Select only the column we require
# It is a necessary step for MOFA as it will not run if there are more than one
# column
colData(mae_day_60) <- colData(mae_day_60)[ , c("mass_category"), drop = FALSE]

# Extract only transformed metagenomic assays for MOFA+ analysis
assays(mae_day_60[[2]]) <- assays(mae_day_60[[2]])[names(assays(mae_day_60[[2]])) %in% c("clr")]

# Transform MAE object to MultiAssayExperiment
model <- create_mofa_from_MultiAssayExperiment(
    mae_day_60,
    group = "mass_category",
    extract_metadata = TRUE
)

# Set model's options
model_opts <- get_default_model_options(model)
model_opts$num_factors <- 5
train_opts <- get_default_training_options(model)

# Change convergence mode to slightly improve accuracy
train_opts$convergence_mode <- "medium"

# Prepare MOFA model
model <- prepare_mofa(
  object = model,
  model_options = model_opts,
  training_options = train_opts
)

# Train model
model <- run_mofa(model, use_basilisk = TRUE)
```

## Pearson correlation between factors

For sanity check, we expect factors to be uncorrelated.

```{r check_ft}
#| fig-width: 10
plot_factor_cor(
  model,
  method = "pearson",
  cl.ratio = 0.2,
  tl.srt = 0,
  title = "Pearson correlation between factors",
  mar=c(0, 0, 2, 0),
)
```
Overall, we do not observe highly correlated factors which is the

## Visualization of MOFA analysis

### Variance explained

Next, we will plot the variances explained by each factor.


```{r var_factor1}
plot_variance_explained(model, x = "group", y = "view", factor = 1, legend = T)
```

Factor 1 captures the variances explained in metagenomic view across both
mass categories.


```{r var_factor2}
plot_variance_explained(model, x = "group", y = "view", factor = 2, legend = T)
```

On the other hand, factor 2 captures variance explained in fatty acid view,
also across both mass categories.

```{r var_factor3}
plot_variance_explained(model, x = "group", y = "view", factor = 3, legend = T)
```
Factor 3 is similar to factor 2 but the variance explained numbers are lower.

We can also summarize the total variance explained in one plot.

```{r}
plot_variance_explained(model, x = "group")
```

## Plot factor

We can now plot single factors. For demonstration purposes, we will focus on
the first three factors and color the samples by treatment group (control and
treatment).

```{r plot_factor}
set.seed(42)
plot_factor(model,
  factors = c(1, 2, 3),
  color_by = "mass_category",
  scale = TRUE,
  add_violin = TRUE,
  color_violin = TRUE,
) +
  labs(fill = "Mass category") +
  scale_fill_hue(
    labels = c(
      "Heavy", "Light"
    )
  )
```
## Plot weights

The next step is to have a deeper look inside the observations we found above.
We can plot factor weight that should show us what fatty acids and bacterial
genera have the highest positive or negative impact on the selected factors.

### Plot top weights

It is possible to plot top weight per each view per each factor.

```{r top_weight_visualization, fig.width=8}
custom_plotter <- function(name, factor) {
    p <- plot_top_weights(
        model,
        view = name,
        factors = factor,
        nfeatures = 6
    ) +
    labs(title = paste0("Top weights of the ", name, " assay for factor ", factor))
    return(p)
}

custom_plotter("metagenomic_amplicon", factor = 1)
custom_plotter("fatty_acids_mg", factor = 2)
custom_plotter("fatty_acids_mg", factor = 3)
```

### Plot weights per factor

We can also plot top weights per view for a selection of factors to have a better
overview of the impacts of different features on factors.

```{r weight_visualization2, fig.width=15}
plot_weights(
    model,
    view = 2,
    nfeatures = 10,
    factors = 1,
    text_size = 4,
    ) +
    labs(title = "Top weights for the first factor in metagenomic view") +
  theme(plot.title = element_text(size = 20),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15)
  )
```

```{r}
plot_weights(
    model,
    view = 1,
    nfeatures = 10,
    factors = 2,
    text_size = 4,
    ) +
    labs(title = "Top 10 weights for the second factor in fatty acid view") +
  theme(plot.title = element_text(size = 10),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15)
  )
```


```{r}
plot_weights(
    model,
    view = 1,
    nfeatures = 10,
    factors = 3,
    text_size = 4,
    ) +
    labs(title = "Top 10 weights for the third factor in fatty acid view") +
  theme(plot.title = element_text(size = 10),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15)
  )
```

## IntegratedLearner

IntegratedLearner R package is build on SuperLearner package which uses Bayesian
ensemble method to predict desired variables by utilizing the information across
multi omic layers. The advantage of such method compared to traditional frequentist
approaches is the option to account for quantifiable uncertainty.

IntegratedLearner allow us to test multiple machine learning algorithms. Thus,
we will test two: Random Forest and Bayesian Additive Regression Trees machines
(BART machines). Both methods use trees as their basis and might sound very similar
since they are both ensemble machine learning algorithms.

Random Forest employs multiple decisions trees, where each tree performs a
prediction to, for example, classify an object. In the final stage, the most
"voted" class will be assigned to the object.

BART machines algorithms employ regression trees, where each tree makes one _weak_
prediction, i.e., explains a tiny component of an outcome. BART then combines
these _weak_ predictions to create a stronger prediction, while accounting for
uncertainty.

Random Forest algorithm is used for classification. In our case, we apply it to
investigate whether we can reliable classify salmons into "heavy" (above mass
median) or "light" (below or equal to mass) salmons. We also attempt to classify
salmons into "treatment" and "control" groups. Previously, we did not see any
difference between the groups when using Bray-Curtis distances for metagenomic
data. Thus, we are interested in understanding whether we are able to classify
them into two different groups if we combine the omic data.

BART machines algorithm can be used for continuous data, such as host gutted mass.
We are not directly interested in predicting salmon masses but rather in investigating
what species and fatty acids have the greatest impact on the mass. With BART
machines, we can use variable inclusion proportion to estimate the weight each
feature holds in prediction results. It allows us to indirectly list
the most important features from metagenomic and fatty acid datasets.
Combined with the relative importance of each layer (metagenomics or fatty acids),
we can output the most promising features for the subsquent analyses.

### Data preparation

We will be only using data at day 60 after salmons have grown and been subjected
(treatment) or not (control) to the algae meal. 

```{r extract_mae_data_day_60}
# Get colData from MAE object at day 60
mae_day_60_coldata <- colData(mae_day_60)

# Add treatment_group to colData(mae_day_60) that was removed for MOFA analysis

# Add treatment_group (control vs. treatment) to colData of MAE at day 60
mae_day_60_coldata <- merge(colData(mae_sub)["treatment_group"], colData(mae_day_60), by = 0)

# Add host.gutted.weight to colData(mae_day_60)
mae_day_60_coldata <- merge(colData(mae_sub)[c("host.gutted.mass", "animal")],
                            mae_day_60_coldata,
                            by = "animal", by.y = "Row.names")
```

We also need to prepare the data for the IntegratedLearner package. We are
using MultiAssayExperiment container, so extracting the data is trivial and
can be performed with basic R transformations.

```{r prepare_data_integrated_learner1}
# Create feature dataframe for IntegratedLearner
metabolomics_df <- mae_day_60[["fatty_acids_mg"]] |>
  assay("log10") |>
  as.data.frame()
metagenomics_df <- mae_day_60[["metagenomic_amplicon"]] |>
  assay("clr") |>
  as.data.frame()

# Replace "sample" names to animal accession numbers
names(metabolomics_df) <- colData(mae_day_60[["fatty_acids_mg"]])[, "animal"]
names(metagenomics_df) <- colData(mae_day_60[["metagenomic_amplicon"]])[, "animal"]

# Join feature tables together
feature_table <- rbind(metagenomics_df, metabolomics_df)

# Sanity check: are columns from colData the same as rownames of feature table
all(colnames(metagenomics_df) == rownames(colData(mae_day_60))) # TRUE
all(colnames(metabolomics_df) == rownames(colData(mae_day_60))) # TRUE
```

We also need to retain only features with non-zero variance as these the most
useful for the algorithm.

```{r feature_table_remove_zero_variance}
# Transpose feature table for subsequent filtering
feature_table_t <- as.data.frame(t(feature_table))

# Filter out out near-zero-variance features
nzv <- nearZeroVar(feature_table_t)
features_filtered <- feature_table_t[, -nzv]
features_table <- as.data.frame(t(features_filtered))
```

Next we need to encode mass category string into 0s and 1s.

```{r}
# Y column for sample_metadata
Y <- as.numeric(factor(mae_day_60_coldata$mass_category))
# Change all 1s to 0 and all 2s to 1
Y <- ifelse(Y == 1, 0, ifelse(Y == 2, 1, Y))

# Create sample_metadata dataframe for IntegratedLearner
sample_metadata <- data.frame(
  Y = Y,
  subjectID = colnames(metabolomics_df)
)
rownames(sample_metadata) <- colnames(metabolomics_df)

# Create feature metadata dataframe for metagenomics
feature_metadata_metagenomics <- data.frame(
  featureID = rownames(metagenomics_df),
  featureType = "species"
)
rownames(feature_metadata_metagenomics) <- feature_metadata_metagenomics$featureID

# Create feature metadata dataframe for metabolomics
feature_metadata_metabolomics <- data.frame(
  featureID = rownames(metabolomics_df),
  featureType = "metabolites"
)
rownames(feature_metadata_metabolomics) <- feature_metadata_metabolomics$featureID

# Create feature_metadata dataframe for IntegratedLearner
feature_metadata <- rbind(feature_metadata_metagenomics, feature_metadata_metabolomics)

# Transform featureID into factors
feature_metadata$featureID <- as.factor(feature_metadata$featureID)
```

```{r}
# Mass category distribution (0: heavy, 1: light)
table(sample_metadata$Y)
```

```{r}
# Sanity check
all(rownames(feature_table) == rownames(feature_metadata)) # TRUE
all(colnames(feature_table) == rownames(sample_metadata)) # TRUE
```

### Random forest algorithm

We will split data into train and validation datasets to train the data and
then perform independent validation.

```{r prepared_data_random_forest}
# Set seed for reproduciblity
set.seed(423)

# Split dataframes into train and validation dataframes
feature_table_sample <- sample(
  c(TRUE, FALSE), ncol(feature_table), replace = TRUE, prob = c(0.67, 0.33))
feature_table_train <- feature_table[, feature_table_sample]
feature_table_valid <- feature_table[, !feature_table_sample]

# sample_metadata
sample_metadata_train <- sample_metadata[colnames(feature_table_train), ]
sample_metadata_valid <- sample_metadata[colnames(feature_table_valid), ]

# Sanity check
all(rownames(sample_metadata_train) == colnames(feature_table_train)) # TRUE
all(rownames(sample_metadata_valid) == colnames(feature_table_valid)) # TRUE
```

We apply Random Forest as our base model for per-layer predictions, and non
negative least squares method to make final predictions.

```{r fit_random_forest}
# Random forest fit
rf_fit <- IntegratedLearner(feature_table = feature_table_train,
                               sample_metadata = sample_metadata_train,
                               feature_metadata = feature_metadata,
                               feature_table_valid = feature_table_valid,
                               sample_metadata_valid = sample_metadata_valid,
                               folds = 10,
                               base_learner = "SL.randomForest",
                               meta_learner = "SL.nnls.auc",
                               verbose = TRUE,
                               family = binomial())
```

```{r}
# Visualization of AUC curves to predict heavy vs. light mass categories
plot.obj <- IntegratedLearner:::plot.learner(rf_fit)
```

#### Treatment group

We can test whether predictions of treatment versus control can be made.

After encoding, control is 0, and treatment is 1.

```{r}
metagenomic_data$treatment_group <-
  ifelse(metagenomic_data$treatment_concentration == 0, "control", "treatment")
# colData(mae_sub[["metagenomic_amplicon"]]) <- metagenomic_data

# Set response variable Y to control vs. treatment
Y <- as.numeric(factor(mae_day_60_coldata$treatment_group))

# Change all 1s to 0 and all 2s to 1
# Control: 0
# Treatment: 1
Y <- ifelse(Y == 1, 0, ifelse(Y == 2, 1, Y))

# Create sample_metadata dataframe for IntegratedLearner
sample_metadata <- data.frame(
  Y = Y,
  subjectID = colnames(metabolomics_df)
)
rownames(sample_metadata) <- colnames(metabolomics_df)

# Split sample_metadata into train and validation dataframes
# feature_table and feature_metadata remain the same
sample_metadata_train <- sample_metadata[colnames(feature_table_train), ]
sample_metadata_valid <- sample_metadata[colnames(feature_table_valid), ]

# Sanity check
all(rownames(sample_metadata_train) == colnames(feature_table_train)) # TRUE
all(rownames(sample_metadata_valid) == colnames(feature_table_valid)) # TRUE
```

We apply th same non-negative least square meta-learner as before.

```{r}
# Random forest fit for treatment vs. control
rf_fit <- IntegratedLearner:::IntegratedLearner(feature_table = feature_table_train,
                               sample_metadata = sample_metadata_train,
                               feature_metadata = feature_metadata,
                               feature_table_valid = feature_table_valid,
                               sample_metadata_valid = sample_metadata_valid,
                               folds = 10,
                               base_learner = "SL.randomForest",
                               meta_learner = "SL.nnls.auc",
                               verbose = TRUE,
                               family = binomial())
```

```{r}
# Visualization (treatment vs. control)
plot.obj <- IntegratedLearner:::plot.learner(rf_fit)
```

Predictions for training data of random forest algorithm.

```{r}
rf_fit$yhat.train
```

### Bayesian Additive Regression Trees machine algorithm

#### host.gutted.mass

For BART machine algorithm we are using the continuous response variable: `host.gutted.mass`.


```{r}
# Y column for sample_metadata
# Create sample_metadata dataframe for IntegratedLearner
Y <- as.numeric(mae_day_60_coldata$host.gutted.mass)
sample_metadata_gutted_weight <- data.frame(
  Y = Y,
  subjectID = colnames(metabolomics_df)
)
# Add rownames to animal HoloFood IDs
rownames(sample_metadata_gutted_weight) <- sample_metadata_gutted_weight$subjectID
sample_metadata_gutted_weight_train <- sample_metadata_gutted_weight[sample_metadata_train$subjectID, ]
sample_metadata_gutted_weight_valid <- sample_metadata_gutted_weight[sample_metadata_valid$subjectID, ]


all(rownames(sample_metadata_gutted_weight_train) == colnames(feature_table_train)) # TRUE
all(rownames(sample_metadata_gutted_weight_valid) == colnames(feature_table_valid)) # TRUE
rownames(sample_metadata_gutted_weight) <- colnames(metabolomics_df)
```


```{r}
# predict() function is conflicting with one of bartMachine algorithms
# so we need to unload it from namespace
unloadNamespace("MOFA2")

bart_fit <- IntegratedLearner:::IntegratedLearner(
                    feature_table = feature_table_train,
                    sample_metadata = sample_metadata_gutted_weight_train,
                    feature_metadata = feature_metadata,
                    feature_table_valid = feature_table_valid,
                    sample_metadata_valid = sample_metadata_gutted_weight_valid,
                    folds = 10,
                    base_learner = "SL.BART",
                    meta_learner = "SL.nnls.auc",
                    family = gaussian())
# Visualization
plot.obj <- IntegratedLearner:::plot.learner(bart_fit)
```

Since we are employing Bayestin statistics we can generate credible intervals

```{r}
# Generate credible intervals
# Requires longitudinal data for extracting very important features
bart_weights <- bart_fit$weights

bart_dataX <- bart_fit$X_train_layers
bart_dataY <- bart_fit$Y_train

bart_post.samples <- vector("list", length(bart_weights))
names(bart_post.samples) <- names(bart_dataX)

# Is not serialized when using binomial family
for (i in seq_along(bart_post.samples)) {
  bart_post.samples[[i]] <- bart_machine_get_posterior(bart_fit$model_fits$model_layers[[i]],
                                                       bart_dataX[[i]])$y_hat_posterior_samples
}

bart_weighted.post.samples <- Reduce("+", Map("*", bart_post.samples, bart_weights))
rownames(bart_weighted.post.samples) <- rownames(bart_dataX[[1]])
```

```{r}
#| fig-width: 10
#| fig-height: 7
# Show credible intervals for hosted.gut.weight
temp <- caterplot(t(bart_weighted.post.samples),
          horizontal = FALSE, add = FALSE)
points(bart_dataY[temp])
title(main ="", xlab = "Observations", ylab = "Host gutted mass (in gramms)",
       line = NA, outer = FALSE)
```


Finally, as stated in the introduction to IntegratedLearner section,
we are able to output the relative importance of each layer and the most important
features in each layer.

```{r}
### Find most important features ###
omicsEye_theme <- function() {
# set default text format based on categorical and length
  angle = 45
  hjust = 1
  size = 6
  return (ggplot2::theme_bw() + ggplot2::theme(
    axis.text.x = ggplot2::element_text(size = 8, vjust = 1, hjust = hjust, angle = angle),
    axis.text.y = ggplot2::element_text(size = 8, hjust = 1),
    axis.title = ggplot2::element_text(size = 10),
    plot.title = ggplot2::element_text(size = 10),
    plot.subtitle = ggplot2::element_text(size = 8),
    legend.title = ggplot2::element_text(size = 6, face = 'bold'),
    legend.text = ggplot2::element_text(size = 7),
    axis.line = ggplot2::element_line(colour = 'black', size = .25),
    ggplot2::element_line(colour = 'black', size = .25),
    axis.line.x = ggplot2::element_line(colour = 'black', size = .25),
    axis.line.y = ggplot2::element_line(colour = 'black', size = .25),
    panel.border = ggplot2::element_blank(),
    panel.grid.major = ggplot2::element_blank(),
    panel.grid.minor = ggplot2::element_blank())
  )
}

myColtmp <- c("cornflowerblue","darkcyan","orchid4",
            "brown","goldenrod4","mistyrose4","darkgreen","purple")


VIMP_stack <- cbind.data.frame(bart_fit$weights)

colnames(VIMP_stack) <- c("mean")
VIMP_stack$sd <- NA
VIMP_stack$type <- "stack"


# Microbiome
qq <- bartMachine::investigate_var_importance(bart_fit$model_fits$model_layers$species, plot = FALSE)

VIMP_microbiome <- cbind.data.frame(qq$avg_var_props, qq$sd_var_props)
colnames(VIMP_microbiome) <- c("mean", "sd")
VIMP_microbiome$type <- "species"

# Metabolomics
qq <- bartMachine::investigate_var_importance(bart_fit$model_fits$model_layers$metabolites, plot = FALSE)

VIMP_metabolites <- cbind.data.frame(qq$avg_var_props, qq$sd_var_props)
colnames(VIMP_metabolites )<- c("mean", "sd")
VIMP_metabolites$type <- "metabolites"

VIMP <- as.data.frame(rbind.data.frame(VIMP_stack,
                                     VIMP_microbiome[1:20,],
                                     VIMP_metabolites[1:20,]))


VIMP <- rownames_to_column(VIMP, "ID")


p4 <- VIMP %>%
  filter(type == "stack") %>%
  arrange(desc(mean))  %>%
  ggplot(aes(y = mean, x = reorder(ID,-mean))) +
  geom_bar(stat = "identity", fill = 'darkseagreen') +
  theme_bw() +
  omicsEye_theme() +
  ylab("Layer Weights") +
  xlab("")


p5 <- VIMP %>%
  filter(type %in% c('species', 'metabolites')) %>%
  arrange(mean) %>%
  mutate(ID = str_replace_all(ID, fixed("_"), " ")) %>%
  mutate(type = factor(type,
                       levels = c('species', 'metabolites'),
                       labels = c('species', 'metabolites'))) %>%
  ggplot(aes(reorder(ID, -mean), mean, fill = type)) +
  facet_wrap(.~ type, scale = 'free') +
  geom_bar(stat = "identity", fill = "lightsalmon") +
  geom_errorbar(aes(ymin=ifelse(mean-sd>0,mean-sd,0), ymax=mean+sd), width=.2, position=position_dodge(.9)) +
  theme_bw() +
  coord_flip() +
  omicsEye_theme() +
  theme (strip.background = element_blank()) +
  ylab('Inclusion proportion') +
  xlab('')


plot_grid(p4,
             ncol = 1,
             labels = c('Estimated IntegratedLearner layer weights'),
             label_size = 8, vjust = 0.1)+
  theme(plot.margin = unit(c(0.5,0.5,0.5,0.5), "cm"))
```

```{r}
plot_grid(p5,
             ncol = 1,
             labels = c("Top features of microbiome and metabolites layers"),
             label_size = 8, vjust = 0.1)+
  theme(plot.margin = unit(c(0.5,0.5,0.5,0.5), "cm"))
```

## Conclusions

The present case study has demonstrated how easy and fast it is to
download large dataset and transform the data into a MultiAssayExperiment, which
in turn gives the researchers access to an extensive plethora of downstream
tools, such mia and MOFA2 that can be used to pre-process and visualize the
multi-omics data.

```{r session_info}
sessionInfo()
```

